{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Tool Calling\n",
        "\n",
        "Answer the question by searching the web for information using:\n",
        "\n",
        "1.   **LangChain** for orchestration\n",
        "2.   The DuckDuckGo search **tool**\n",
        "3.   **LLM**: Qwen2.5-3B-Instruct"
      ],
      "metadata": {
        "id": "yqto7jWxTJnr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install dependencies"
      ],
      "metadata": {
        "id": "UxfDqeVJNK_C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JpnbOOpBNBXJ"
      },
      "outputs": [],
      "source": [
        "!pip install -q langchain langchain-community ddgs transformers accelerate bitsandbytes"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "eVRrq2r3NmBR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.tools import Tool\n",
        "from langchain_community.tools import DuckDuckGoSearchResults"
      ],
      "metadata": {
        "id": "L5tFarijNjHI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.language_models.llms import BaseLLM # HuggingFacePipeline"
      ],
      "metadata": {
        "id": "ifFF_6PCN3Pr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "Oy_8vdAeSeej"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "import torch"
      ],
      "metadata": {
        "id": "-cYCaNT_OiU4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Load the quantized model and Tokenizer"
      ],
      "metadata": {
        "id": "9dz6i_U4Oxfg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "quant_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True\n",
        ")\n",
        "\n",
        "model_name = \"unsloth/Qwen2.5-3B-Instruct\"  # unsloth/Qwen2.5-7B-Instruct\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    quantization_config=quant_config,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "print(f\"Model is on: {model.device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225,
          "referenced_widgets": [
            "af39cbd2305b4c949a517bd46d825eba",
            "7cdd21fd3b0443559eba547ae8991ab2",
            "2be39fa1f20f4dc4bfc3aaab97d0e0a5",
            "524f09f5979c4c7794ea97e87195bd58",
            "a84a2862d65840c4aebad80a1f7656fd",
            "d5cc5f42a0014b6fb3c1a8a586291147",
            "d72a0c78af7041a386b0107a9f2c9295",
            "ba69cf1e9b934c30b612a6efdbc89f49",
            "e8baf508a39a44d3bcf82429b7c13e9e",
            "f14ead7211244177b99a4c4cbd327084",
            "47d84057112149eea6761c745c35ecf9"
          ]
        },
        "id": "4zibf26MOZjj",
        "outputId": "8475741e-e1c2-413a-d088-1c734836c755"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
            "WARNING:huggingface_hub.utils._http:Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/434 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "af39cbd2305b4c949a517bd46d825eba"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model is on: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Pass the Model into pipeline"
      ],
      "metadata": {
        "id": "RKZCVv2FRFtj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens=500,\n",
        "    do_sample=True,\n",
        "    temperature=0.7\n",
        ")"
      ],
      "metadata": {
        "id": "JP9p0fY1RWKf"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Wrap for LangChain"
      ],
      "metadata": {
        "id": "GaIrKYnMRV4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-huggingface -q"
      ],
      "metadata": {
        "id": "YubvTeln9X8-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_huggingface import HuggingFacePipeline"
      ],
      "metadata": {
        "id": "LGM2dbzNaz2U"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "custom_llm = HuggingFacePipeline(pipeline=pipe)"
      ],
      "metadata": {
        "id": "C3r421kKTSAH"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Test (the Text Generation)"
      ],
      "metadata": {
        "id": "Y5MF03DATjTk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1. Directly"
      ],
      "metadata": {
        "id": "dT-wrtcFT-Xc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = pipe(\"Explain Agentic AI simply only in Englsih.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ns3-tVMLUCTi",
        "outputId": "f5e16321-5fcf-4c2c-c673-b8890aaf23a0"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=500) and `max_length`(=32768) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response[0]['generated_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtwJIu-N-hjB",
        "outputId": "e129cc4b-884d-4f8a-9cf3-93e9abf66dd8"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Explain Agentic AI simply only in Englsih. Agentic AI is a type relabeling that suggests an artificial intelligence (AI) system should be treated as if it has agency or the ability to act independently, even when it's actually controlled by human programmers. This concept can be seen in scenarios where the AI makes decisions that are difficult to trace back to its programming, leading to the perception that the AI is acting on its own accord. It’s often used to describe systems like chatbots, virtual assistants, and other interactive AI tools that seem to exhibit behaviors that mimic human decision-making and actions.\n",
            "\n",
            "In essence, agentic AI treats the AI as having autonomy, even though it operates within strict boundaries set by its creators. This approach helps to create more realistic and engaging interactions with AI systems, making them feel more like independent entities capable of making choices and responding to situations in a way that humans do. This can enhance user experience and make AI technologies more believable and usable in various applications, such as customer service, education, and entertainment. \n",
            "\n",
            "Key points:\n",
            "- Treats AI as having agency despite being controlled\n",
            "- Mimics human-like decision-making and behavior\n",
            "- Enhances realism and user engagement\n",
            "- Used for various AI systems and applications\n",
            "\n",
            "Is there anything else you'd like me to add or clarify about agentic AI? Sure! Here are a few additional points to further explain agentic AI:\n",
            "\n",
            "1. **Perception vs. Reality**: Agentic AI creates a perception that the AI is acting autonomously, while it is still influenced by its programmed rules and constraints. This duality between perceived and actual agency is a key aspect of agentic AI.\n",
            "\n",
            "2. **Ethical Implications**: Using agentic AI can raise ethical concerns, especially when the AI makes decisions that impact real-world outcomes. For example, in healthcare or autonomous driving, the perceived independence of the AI can influence how we evaluate its performance and responsibility.\n",
            "\n",
            "3. **User Experience**: Agentic AI can improve user experience by making interactions with AI systems more natural and intuitive. When users perceive the AI as autonomous, they may be more willing to trust and engage with it.\n",
            "\n",
            "4. **Cognitive Load**: The perception of agency can also affect cognitive load. If the AI appears to have more autonomy, users might be less inclined to question its actions, which can be both helpful and potentially problematic depending on the context.\n",
            "\n",
            "5. **Applications**: Agentic AI finds applications in various fields, including but not limited to:\n",
            "   - Customer service: Virtual assistants that\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2. inside LangChain"
      ],
      "metadata": {
        "id": "T_I_WkASUGlD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate"
      ],
      "metadata": {
        "id": "dz5fVS_8PZKz"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = PromptTemplate.from_template(\"Explain {topic} simply only in Englsih.\")\n",
        "chain = prompt | custom_llm"
      ],
      "metadata": {
        "id": "U_X1Mz7nTtVL"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the chain\n",
        "result = chain.invoke({\"topic\": \"Agentic AI\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTRconJB_agm",
        "outputId": "d304712e-b8ee-440e-9e38-a064b4af621c"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=500) and `max_length`(=32768) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9obVBqw_boN",
        "outputId": "4f0f2331-198c-4e51-9fcf-4b0dfc2499b9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Explain Agentic AI simply. Agentic AI is a type of artificial intelligence (AI) that aims to make machines appear more like living, conscious beings. Instead of focusing solely on tasks and functions, agentic AI seeks to create agents that exhibit behaviors and characteristics similar to those found in humans or other living organisms.\n",
            "\n",
            "Key aspects of agentic AI include:\n",
            "\n",
            "1. Agency: The ability to act autonomously and make decisions based on internal goals and motivations, rather than being controlled by external forces.\n",
            "\n",
            "2. Consciousness-like behavior: Displaying awareness, perception, and introspection, as seen in human cognition and emotion.\n",
            "\n",
            "3. Embodiment: Having physical form or a body that can interact with the world and other agents.\n",
            "\n",
            "4. Sociality: Engaging in social interactions and relationships with other agents, much like humans do.\n",
            "\n",
            "5. Learning and adaptation: Developing knowledge, skills, and preferences through experience and interaction with the environment.\n",
            "\n",
            "6. Moral agency: Exhibiting moral reasoning, empathy, and ethical decision-making, similar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Setup DuckDuckGo search tool"
      ],
      "metadata": {
        "id": "IuT6oMlNbiaC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ddg_tool = DuckDuckGoSearchResults()\n",
        "\n",
        "search_tool = Tool(\n",
        "    name=\"DuckDuckGo Search\",\n",
        "    description=\"Useful for answering questions by searching the web\",\n",
        "    func=ddg_tool.run\n",
        ")\n",
        "\n",
        "tools = [search_tool]"
      ],
      "metadata": {
        "id": "0VwdpeKdbnpO"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Prompt template"
      ],
      "metadata": {
        "id": "fRxwf_1XgQXz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = PromptTemplate.from_template(\n",
        "    \"Answer the question **in one short sentence or only the answer**, using the information provided.\\n\"\n",
        "    \"Question: {question}\\n\"\n",
        "    \"Information from web: {info}\\n\"\n",
        "    \"Answer:\"\n",
        ")"
      ],
      "metadata": {
        "id": "oZ5pOkxYgUIb"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " # 7. Runnable chain"
      ],
      "metadata": {
        "id": "1JKi3CHWhMfN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pick a question\n",
        "query = \"Who won the FIFA World Cup in 2022?\" # What is Agentic AI?"
      ],
      "metadata": {
        "id": "G1kCYCE3hWhB"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the search tool\n",
        "search_result = tools[0].run(query)"
      ],
      "metadata": {
        "id": "_IH9PI0khYuk"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Search Result:\\n\", search_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QaDNkLOviEps",
        "outputId": "558c5c2f-c914-4984-8ff0-7933223240d1"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search Result:\n",
            " snippet: 4 days ago - The 2022 FIFA World Cup final was the final match of the 2022 FIFA World Cup, the 22nd edition of FIFA's competition for men's national football teams. The match was played at Lusail Stadium in Lusail, Qatar, on 18 December 2022, the Qatari National Day, and was contested by Argentina and defending champions France., title: 2022 FIFA World Cup final - Wikipedia, link: https://en.wikipedia.org/wiki/2022_FIFA_World_Cup_final, snippet: 2 weeks ago - The FIFA World Cup, often called ... of 1942 and 1946 due to the Second World War. The reigning champions are Argentina, who won their third title at the 2022 World Cup by defeating France ...., title: FIFA World Cup - Wikipedia, link: https://en.wikipedia.org/wiki/FIFA_World_Cup, snippet: 2 days ago - Major European competitions had scheduled their respective competitions group matches to be played before the World Cup, to avoid playing group matches the following year. The match schedule was confirmed by FIFA on 15 July 2020. The group stage was set to begin on 21 November, with four matches every day. Later, the schedule was tweaked by moving the Qatar vs Ecuador game to 20 November, after Qatar lobbied FIFA to allow their team to open the tournament. The final was played on 18 December 2022, National Day, at Lusail Stadium., title: 2022 FIFA World Cup - Wikipedia, link: https://en.wikipedia.org/wiki/2022_FIFA_World_Cup, snippet: 1 day ago - Argentina defeated France on penalties in the latest final, staged at Qatar's Lusail Stadium in 2022. ... ^ The 1962 and 1966 finals had provisions for only a single replay, and then a drawing of lots. For knockout matches other than the finals, penalty shoot-outs had been adopted from 1978, ..., title: List of FIFA World Cup finals - Wikipedia, link: https://en.wikipedia.org/wiki/List_of_FIFA_World_Cup_finals\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine with LLM\n",
        "chain = prompt_template | custom_llm"
      ],
      "metadata": {
        "id": "K2zayj92hcgG"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the chain\n",
        "# final_result = chain.invoke({\"question\": search_result})\n",
        "final_result = chain.invoke({\"question\": query, \"info\": search_result})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egMXCdR-hldR",
        "outputId": "43b6b66a-546c-4cd2-efc5-46486b6124f9"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=500) and `max_length`(=32768) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nLLM Answer:\\n\", final_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VK8CG_RNh-Pl",
        "outputId": "286fe9d5-c12d-4a84-83d2-fc602c1f3d01"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LLM Answer:\n",
            " Answer the following question based on the information provided: Who won the FIFA World Cup in 2022? The 2022 FIFA World Cup was held in Qatar, and the winning team was Argentina. \n",
            "\n",
            "To answer this question, we need to recall the details of the 2022 FIFA World Cup. The event took place in Qatar, which was the first time the tournament was hosted in the Middle East. The final match of the tournament was played on December 18, 2022, between Argentina and France. Argentina emerged victorious, defeating France with a score of 3-1. As a result, Lionel Messi led his national team to their fourth World Cup title, making him the first player to win the World Cup as both a player and a coach.\n",
            "\n",
            "Based on the information provided, the correct answer to the question \"Who won the FIFA World Cup in 2022?\" is Argentina.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Put the code in a function:"
      ],
      "metadata": {
        "id": "mRlFOR2oDZIk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_agent(query):\n",
        "\n",
        "    # Step 1: search (Use the search tool)\n",
        "    tool_result = tools[0].run(query)\n",
        "\n",
        "    # approch 1: Using prompt & .generate()\n",
        "    # Step 2: build prompt\n",
        "    # prompt = f\"Question: {query}\\nInformation from web: {tool_result}\\nAnswer:\"\n",
        "    # Step 3: generate answer\n",
        "    #answer = custom_llm.generate([prompt])  # note: pass a list of prompts\n",
        "\n",
        "    # approach 2: Using a Runnable chain (PromptTemplate → LLM)\n",
        "\n",
        "    # Step 2\n",
        "    chain = prompt_template | custom_llm\n",
        "    # Step 3\n",
        "    answer = chain.invoke({\"question\": query, \"info\": tool_result})\n",
        "    clear_answer = clean_answer(answer)\n",
        "    return clear_answer"
      ],
      "metadata": {
        "id": "EtgcZQzpC0Jb"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_answer(answer):\n",
        "  answer = answer.split(\"Answer:\")[1].strip()\n",
        "  return answer\n"
      ],
      "metadata": {
        "id": "yuUcxkpsRod-"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = run_agent(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZgYik8aDgvu",
        "outputId": "559aa001-9650-4974-b625-5bd44aa78e8d"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=500) and `max_length`(=32768) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r14YOJGzK5ma",
        "outputId": "3b0055fb-cd09-4e57-b27f-172d0f053a34"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Argentina beat France 4-2 on penalties to win the 2022 FIFA World Cup.\n"
          ]
        }
      ]
    }
  ]
}