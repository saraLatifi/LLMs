{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Test some parameters**"
      ],
      "metadata": {
        "id": "DTurDTueFxeO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ozz3rCFeFsQP",
        "outputId": "bc0075ba-f672-419a-f0b9-cfa0ebd40ce3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.20.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.36.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2025.11.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import AutoModelForSeq2SeqLM\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import GenerationConfig"
      ],
      "metadata": {
        "id": "40-kUSjfF1BL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hf_dataset_name = \"knkarthick/dialogsum\"\n",
        "dataset = load_dataset(hf_dataset_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345,
          "referenced_widgets": [
            "77dc3a5817d24c41980efbffd4f70471",
            "e415c5480d06426696b9093299ed651f",
            "f5f71699e456420aae10fcb2d2030798",
            "2c75c25b65d040a9808b2d54d8f9284f",
            "fd28108694aa4ec6bbd0582512f0f236",
            "e8120aa690274d209d9671b902457869",
            "6320fd3851274766829b6372d3e93eda",
            "afbc5eddb1624dd0baf36eb34d501fd6",
            "50895692d6594b478a28a71cb93f3eaa",
            "19e5d6814e4c4b26b98c6e12f708fa61",
            "533fd6fcd3a54d57883856915e8dda0d",
            "8e0248b7ab3c4c61af504032bbc080b6",
            "a0d4d90d0cef4596aa69e5d5f6081fe2",
            "72c7c51947704fd8a4ca09d27a2dbebf",
            "5a93f09dda3b4e52971ffc2c363ba57e",
            "aa894ad94592462ebf3da8e3a940434a",
            "fcb3e9bfbe214e7fbc5c3aa811d57d32",
            "28a02a95f8f94662bdb138d9a205a51f",
            "fbebe85aa7d2476c9e554d2817c01fa0",
            "678f6e9305c24e949b8ea7af8466b5a7",
            "c3bd36bdf01f4688a60dcdb49bd48171",
            "f21fd1e8c3a44b7281fc10d2a5336030",
            "4ccf51beaf954ba2b8fc075ba72b9eaa",
            "c15ff049d5c747dfae2c9ff092b45fbf",
            "df5aca380b1c49d185ae966e93bdee67",
            "ec7a34564b6c4853b102ddcfccaa2941",
            "b9f8c2c3ae5a4e2e9cbf1ebc8184bba7",
            "b57dec7317394e9c94d4a25f652ff3a2",
            "38081a672f4442c1b248f4a7cc761267",
            "df5baa9512e442749e0848751001efa3",
            "0bf95be536534102847f797cf6871b54",
            "0fbe4fd1209c4b4fa6b2d5a35bd94a0b",
            "ecbb7d56ee674cf591c55ad9f962664f",
            "5d28995397a4411687eb53c92383a574",
            "b9f40d04a85640e2aec46cca784e3f20",
            "b631fbf441b44a8eab60f0118f52858c",
            "89f7c1186dde46f990d7c9bae05ee229",
            "50bbc2d37ca847678b049de926b86fec",
            "1374e2cc027347e1a3efcadf07f95355",
            "2702995e79954182943494ca116a4f2a",
            "fd279a66781940b792f831e1018b1e86",
            "ec775d2674ae4c8db2af23ca678a0754",
            "5feec81053184b1eb899319c62c3bff1",
            "933c17ab5af547e6906caa8cf2be2985",
            "3ddd6dab0fec4ed6877a71d4af3ca4b2",
            "e9c0050db8394c37892041c1d291dd8b",
            "b678c03fd93944189c1dfce3dc164f94",
            "ab13862fff794fc098545a2c90e38a32",
            "1d8b01de92ae4432be885b3cbe5553a2",
            "f5458b3623104288acb1bf408142d39c",
            "b440fbd71c8c4d3ab33cd895ae741d6c",
            "281e1feb71e845cd8b11917ef91f2054",
            "a860d3866d97435f8355785e0883fbd9",
            "c7e84949bc3a464182728ac480d8b6b7",
            "784507d78a9847f188b9b500baa18281",
            "0854a6cc09394daea1f8d329c0a50b60",
            "104cc14e71844da189848f85f463327c",
            "715b2da7fe114b4db7e8734c0a243557",
            "22c4a2abfc8d43f98fc70f2476e26ce0",
            "4124d04ede314e6580824154c89b5906",
            "d22970b23dcf4ed3bf8c182e40894215",
            "9b99d4276fb44335889d0f78484472c3",
            "98d65452f0bd46a09bde3d875db10af5",
            "63db7f3a64cd4d75ae3d6c69871c7657",
            "04e4409476c44100be4c073c7d382495",
            "41021d7ea9014508992a47681dbea91a",
            "d5d8e6b44d2e4923aed3e061c0582261",
            "87105538ded14b10b24843d392389d7a",
            "08f37fe96a504b9ea48eb88f9204dd3f",
            "12ec0c8fdf654a809b68e94934931b3e",
            "c16de48bfff4493ebbb94e6912d10cfd",
            "5a3194ccbeff4d06849bf81f663b5884",
            "7b4b30b876324479aab2b28b74f2115e",
            "a469ceed0f8d48d2905cfcb9b66d3033",
            "043ae8090cb0447d9f895a3d45aaa385",
            "535604fc7cd44b32889a732d9c3e2bd8",
            "77c12cfff9124931b62b21ba4f359dbd"
          ]
        },
        "id": "UhhPVOfpF2uX",
        "outputId": "d0f88352-87b9-460b-a593-e0fb593b2fe9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "77dc3a5817d24c41980efbffd4f70471"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train.csv:   0%|          | 0.00/11.3M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8e0248b7ab3c4c61af504032bbc080b6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "validation.csv: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4ccf51beaf954ba2b8fc075ba72b9eaa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "test.csv: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5d28995397a4411687eb53c92383a574"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/12460 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3ddd6dab0fec4ed6877a71d4af3ca4b2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/500 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0854a6cc09394daea1f8d329c0a50b60"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/1500 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d5d8e6b44d2e4923aed3e061c0582261"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'google/flan-t5-base'\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241,
          "referenced_widgets": [
            "c043c503b70a48079f380b0b72dd0641",
            "9494abcc2f494eb39caa2d8613d42aee",
            "42a9e27aae6c45ce803f9bbd1a2c579d",
            "ff0e947060fc422cbf28568956eabc75",
            "985a498370474677bc2838445b2b5681",
            "3b9b7c2f1d574ab6b656827c539518ec",
            "c7ee513f207e4526ac661d7c85e01755",
            "312e7861130c4838a0fc17aa10cfb969",
            "d944b5b541d5496b98587ddc174bb9b5",
            "9a03206cae9d45f796f5cb5ac14e380c",
            "a783568939a74f08848efd115b7087bb",
            "f90a72a292094616841e0645550dce55",
            "5242e3a43fd54283be509f921c7ccec2",
            "85f09e5838d64281beafb98cafe6bc69",
            "ba91caca69364da28ae614410989d0f9",
            "4fbd6b70e8e541698bab0227c82e00fe",
            "1e28595992714deab0be371c5c59efa0",
            "d6e51871c44441f8ab1c137ef28efd00",
            "2b3ffb58b9bf42ff8f68d83200e0b4af",
            "df43581eb1794107a4d6e89d1872fda1",
            "55926ae93181400fb8f63d5a8e500d7d",
            "2b1b3dc5da61426e9f56b1b3863d3955",
            "4a4200c91df74657a4afab9c3f45e82e",
            "86ed6a798c704b8ba37499f05059ad05",
            "85791c9567f44aaf9d218d7411388818",
            "7b33bce9e0ec49aa9662786c8d4f842b",
            "d7b1a42b7fbd44ce92754a804cb27d4f",
            "ea06defa2d094d85b59e348c9268aca7",
            "a0c1f929f3cc43e19a8b791aa46b83d3",
            "ae633360a3b94df88a43e84e58b75b5a",
            "57ffcf0e060f44558aa5685c12fc9c9b",
            "825cf389bf884d018b2db1f8fefe814c",
            "c0c168224f5448a0b8147d6de4112f34",
            "577947f5386c4424bf7b784c2ed72aee",
            "d09a22e7dd8049fdaff9ce730c91f059",
            "c96c186ff3aa4d878906ca253203357c",
            "2bbb9dce787c41ac9256d9ebeae0a6a6",
            "2f88e906f10444c99614b04aec9caf9f",
            "910321b0cbfe41558f34fb609e3fae26",
            "d97b4fd54f3943c79ac69fb7636e5aa3",
            "a5dfd17e009d4b6d9cf5115e9e22d948",
            "d29a08b48f3f40ec99b5093dc0ae089b",
            "00552456855142c092251da5d52a4cec",
            "879a4573e545460fb830d124dea89e10",
            "7fc219d0833a47979eeb404d736ba4f1",
            "3f489e1c71bd49228d783f23aaa86db2",
            "1aa0735d8deb4f6ca9ae1a18e7e095c4",
            "7f28870acb16421f93c35f112ffc0b6b",
            "3b257f7ae4c24b7cb73c2750cb5951b4",
            "fe5d00a136d94d9d802e42f52119d36e",
            "fcca64b0830348d0b31811f0c0a87550",
            "80c1cae4aa7943528aa3680174375f03",
            "1a6b0e04a3b94a1e9456deea999dcac3",
            "290400c560b2477bab901130f1cfc8c4",
            "098408865b124a849e313f4ccc5f9e6b",
            "395254ea94034090b91909dc8d5e103b",
            "9b2b456c5c334859868972743d5a31a4",
            "2a08e2b2390a4073b7efd6592cc50b92",
            "8af507a9a3d24d1196f1602ce5f144bb",
            "ca56cbcf19ba4273be4ad6575c38fadc",
            "9de087ef317846598fd3ad5b1f7fbab5",
            "1865700c61b94b3486bbba023ceec433",
            "493e611e9090409f998739c93691430e",
            "c3b46f7a8a874923a19d339f35169954",
            "8f9e370bcbbb4598a5e5bfa418e03c52",
            "39543df7cd3f4e5fb3e0e8e75e8f7abf",
            "f5be1907126343ec827aff652e3e9728",
            "3d31ab536f9f46ce8fb9c84b0ccc3f1f",
            "6b19f83889d54a61948f70cc068a6a3c",
            "0016a506c857471e9c302c681f900ded",
            "6af9828754274597bfaed8ed52d55fb4",
            "1acca67aba214ab79c580371f4d047e0",
            "770e217e50704c7abcc4e28645493871",
            "50d9be8930d14797833bf29de6649a38",
            "a123d0a5d6aa4e57b173a4d357a742ae",
            "58fe915bf05b4fe397e0946eed2d04a0",
            "9c89dddbde3b4fc68c7c2f3c0cb04a36"
          ]
        },
        "id": "c9WB7raIF2rF",
        "outputId": "90fcd15f-ae4a-4844-eef8-bfef74383dd0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c043c503b70a48079f380b0b72dd0641"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f90a72a292094616841e0645550dce55"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4a4200c91df74657a4afab9c3f45e82e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "577947f5386c4424bf7b784c2ed72aee"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7fc219d0833a47979eeb404d736ba4f1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "395254ea94034090b91909dc8d5e103b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f5be1907126343ec827aff652e3e9728"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_prompt(example_indices_full, example_index_to_summarize):\n",
        "  prompt = ''\n",
        "\n",
        "  for index in example_indices_full:\n",
        "    dialogue = dataset['test'][index]['dialogue']\n",
        "    summary = dataset['test'][index]['summary']\n",
        "\n",
        "    # The stop sequence '{summary}\\n\\n\\n' is important for FLAN-T5.\n",
        "    # Other models may have their own preferred stop sequence.\n",
        "    prompt += f\"\"\"\n",
        "Dialogue:\n",
        "\n",
        "{dialogue}\n",
        "\n",
        "summary:\n",
        "{summary}\\n\\n\\n\n",
        "\"\"\"\n",
        "\n",
        "  dialogue = dataset['test'][example_index_to_summarize]['dialogue']\n",
        "\n",
        "  prompt += f\"\"\"\n",
        "Dialogue:\n",
        "\n",
        "{dialogue}\n",
        "\n",
        "Summarize:\n",
        "\"\"\"\n",
        "\n",
        "  return prompt"
      ],
      "metadata": {
        "id": "bk6cOtnhF4tY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_indices_full = [40, 80, 120]\n",
        "example_index_to_summarize = 200\n",
        "\n",
        "few_shot_prompt = make_prompt(example_indices_full, example_index_to_summarize)"
      ],
      "metadata": {
        "id": "zmX7HcAfF9Xm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dialogue = dataset['test'][200]['dialogue']\n",
        "\n",
        "summary = dataset['test'][example_index_to_summarize]['summary']\n",
        "\n",
        "inputs = tokenizer(few_shot_prompt, return_tensors='pt')\n",
        "output = tokenizer.decode(\n",
        "    model.generate(\n",
        "        inputs[\"input_ids\"],\n",
        "        max_new_tokens=50,\n",
        "    )[0],\n",
        "    skip_special_tokens=True\n",
        ")\n",
        "\n",
        "print(f'Dialogue: \\n{dialogue}\\n')\n",
        "\n",
        "print(f'Generated Summary: {output}\\n')\n",
        "\n",
        "print(f'Human Summary: {summary}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzR0JJCHF_FA",
        "outputId": "4b5dff31-4522-42ca-ecba-34b631a9eda6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (809 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dialogue: \n",
            "#Person1#: Have you considered upgrading your system?\n",
            "#Person2#: Yes, but I'm not sure what exactly I would need.\n",
            "#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n",
            "#Person2#: That would be a definite bonus.\n",
            "#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n",
            "#Person2#: How can we do that?\n",
            "#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n",
            "#Person2#: No.\n",
            "#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n",
            "#Person2#: That sounds great. Thanks.\n",
            "\n",
            "Generated Summary: #Person1 wants to upgrade his computer. #Person2 wants to add a painting program to his software. #Person1 wants to upgrade his hardware.\n",
            "\n",
            "Human Summary: #Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **max_new_tokens**\n"
      ],
      "metadata": {
        "id": "1S2r0-PjGCDA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(few_shot_prompt, return_tensors='pt')\n",
        "output = tokenizer.decode(\n",
        "    model.generate(\n",
        "        inputs[\"input_ids\"],\n",
        "        max_new_tokens=10,\n",
        "    )[0],\n",
        "    skip_special_tokens=True\n",
        ")\n",
        "\n",
        "print(f'Generated Summary: {output}\\n')\n",
        "\n",
        "print(f'Human Summary: {summary}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQku5ZvTGDFA",
        "outputId": "0b1a40d2-da58-49de-df63-ec115c64ae71"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Summary: #Person1 wants to upgrade his computer.\n",
            "\n",
            "Human Summary: #Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **do_sample**\n",
        "\n",
        "Default values:\n",
        "\n",
        "```\n",
        "top_k=50  \n",
        "top_p=1.0\n",
        "```"
      ],
      "metadata": {
        "id": "Zz20le8yGHfK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(few_shot_prompt, return_tensors='pt')\n",
        "output = tokenizer.decode(\n",
        "    model.generate(\n",
        "        inputs[\"input_ids\"],\n",
        "        max_new_tokens=50,\n",
        "        do_sample=True       # turn on sampling\n",
        "    )[0],\n",
        "    skip_special_tokens=True\n",
        ")\n",
        "\n",
        "print(f'Generated Summary: {output}\\n')\n",
        "\n",
        "print(f'Human Summary: {summary}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtVPrWvbGM4m",
        "outputId": "176c990b-25c7-4d36-d1ff-8e7e86504c60"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Summary: #Person1 is asking if he has a list of options.\n",
            "\n",
            "Human Summary: #Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **do_sample** + **top_k** & **top_p**\n",
        "\n",
        "Note:\n",
        "\n",
        "```\n",
        "top_k=0    # disables top-k\n",
        "top_p=1.0  # disables top-p\n",
        "```\n"
      ],
      "metadata": {
        "id": "bvmYVklCGQgS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(few_shot_prompt, return_tensors='pt')\n",
        "output = tokenizer.decode(\n",
        "    model.generate(\n",
        "        inputs[\"input_ids\"],\n",
        "        max_new_tokens=50,\n",
        "        do_sample=True,       # turn on sampling\n",
        "        top_k=20,\n",
        "        top_p=0.90\n",
        "    )[0],\n",
        "    skip_special_tokens=True\n",
        ")\n",
        "\n",
        "print(f'Generated Summary: {output}\\n')\n",
        "\n",
        "print(f'Human Summary: {summary}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbQgPDWrGSJ0",
        "outputId": "86d62db5-bf79-4bf5-b220-2f5374fdec35"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Summary: Several software programs are available. Some of them need updating.\n",
            "\n",
            "Human Summary: #Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **temperature** (& **do_sample**)\n",
        "\n",
        "`temperature` **MUST** be used with `do_sample=True`\n",
        "\n",
        "\n",
        "\n",
        "*   temperature < 1 → less random\n",
        "*   temperature > 1 → more random\n",
        "\n",
        "Typical values:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*   temperature → 0 → approximates **greedy** decoding (picks the highest-probability token).\n",
        "*   0 < temperature < 1 → makes output more deterministic (less random).\n",
        "*   temperature = 1 → **default, normal sampling**.\n",
        "*   temperature > 1 → makes output more random (more diverse).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZWaC5hDuGWdC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(few_shot_prompt, return_tensors='pt')\n",
        "output = tokenizer.decode(\n",
        "    model.generate(\n",
        "        inputs[\"input_ids\"],\n",
        "        max_new_tokens=50,\n",
        "        do_sample=True,       # turn on sampling\n",
        "        temperature=0.5\n",
        "    )[0],\n",
        "    skip_special_tokens=True\n",
        ")\n",
        "\n",
        "print(f'Generated Summary: {output}\\n')\n",
        "\n",
        "print(f'Human Summary: {summary}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icPyRswFGX1I",
        "outputId": "2dc9e62d-fe15-486d-eafa-56991e7362f8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Summary: #Person1 proposes some upgrades to his computer software.\n",
            "\n",
            "Human Summary: #Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n"
          ]
        }
      ]
    }
  ]
}