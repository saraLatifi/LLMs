{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Summarization Using a Causal Model**\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RGH6AMcQG-Kp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "z5biJM9H0Gpg",
        "outputId": "6d8965b7-6549-420a-ad5b-01c4456c8794"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.20.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.36.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2025.11.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "k4_ie_G812wM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hf_dataset_name = \"knkarthick/dialogsum\"\n",
        "dataset = load_dataset(hf_dataset_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365,
          "referenced_widgets": [
            "a6e38cf4fb5c4e1c8626147d6924855c",
            "2d9ac434a1554a16979294994bb98540",
            "0551e70c226c40788df7841da71b8617",
            "180e969f309c4a67a055909e02e31f96",
            "208c047e676542fb96475ec0e1df355a",
            "b803d9b102364dc697a72d987c4b0699",
            "e2456bbb954141cf87fe8d570cece35b",
            "e81c43317f614a2ea01bc7229adb1ca7",
            "b2d1a27dab37446996f64ee8d7cfe97a",
            "435802ef8bbb4834bcf2566c48d891da",
            "8faa129e7445434697f1abd272f023ff",
            "348d5bbfa5724681a3d9e0c8cf3265ef",
            "933856d0414f4f36855d6c5178696916",
            "a550581edf0c43a9a3a433eadf87102e",
            "be58fa0266cd479f8e95ef6044783f5b",
            "eb48a6b0d64647c4ba359b35fcb6ff4c",
            "6c4def8106224215b131f6e91ca44d58",
            "702be425d4c74d28a4ac1ecf232617de",
            "05340a44e29b4a98a77ea1d564cf2ea6",
            "57a09802529f488ba08808903901e5c3",
            "2a50d73b279d41999905c6ddd2be035d",
            "c93b8ef4d4d84afda5094bc0cd1df27d",
            "739433542ac24149b5909fa88d665159",
            "f4dece3cdfe04614b259600f5f4f673a",
            "7d33cafd3b214d9599200ea177c346b7",
            "075c66d4e0c34a56878623de0c2822b7",
            "9a393fdfb07c4240bfe7c3210da5a7cb",
            "38d1fea864d2491585d4dc7b4809b265",
            "27e16ba570a74c7bbb38424702a27489",
            "853fa32aa51141c6a3ca95eb2101b8bf",
            "f956cb1bb11f46848d8044a218e131cb",
            "2b0672e700c84ed2a75ec58884e782b3",
            "ff45384f2f3b4a5f8857ba07b2c1207f",
            "fe114f25d39f48f783e9d469ad460eb5",
            "00f72f5373ed4c5ab3a09c958f73b00a",
            "ab3d00bf6f694b05b2f0667d5127556e",
            "be31aa2ea5df44729e03e714341db3a1",
            "882639c4601d4d8698f590a187ce0b8b",
            "639bb0e3efb143d099d9da51ced6b411",
            "78ccb56f308f456f98842c4fb9b93b6b",
            "1b94c496456e42f390aaf7087a0a938e",
            "3c096ad23ed7414eb5608e46bad340d7",
            "0e82996ef59b487383b39984fdbb3010",
            "f43b6bd594ec4fb6bc390711f0e1c006",
            "a05e308a2a4147a4b94c16a35dec3535",
            "9f5d5485b0874bb0a4ce438e773b3520",
            "f2f3706c1d8c42da849b42ebd42372cb",
            "6462d5f77adf4b619387378af52eeb0b",
            "8f072ba380c04f43a2a136bfff01ba60",
            "277c1d4226344689b887734a6bbc7379",
            "ffec0bc1a9ce4ac38894e720b641ee7b",
            "2a091c8e97754be4b0905b161d196228",
            "247fe2a9052c418e92e459dc88940ea2",
            "dfdb67d8938048589a3753497b07cb23",
            "fcf5fad855a342d09dd1b7649f7f8b2a",
            "5e7964873f3b4530a63935e9ad4d661d",
            "e21cf00a336d4a06ae338e0df32d944f",
            "bce04e9021484978b49cb7b52be04cd2",
            "94ed59c4518c4bcca3c8606d3541740f",
            "d82cccb0cf5647079a0fdb905571d245",
            "330da12d297a48cd9e2e33e4fb4a6ff8",
            "87bab561ef5a48f28056141c131711a0",
            "dd3bd09911cc4dbfa3c73f11fae8e7f9",
            "92fd8f45ec2e451aa846bcdcbf37c8fe",
            "07e69cacd76148a69403d5ed58428d29",
            "b204a77cb6f0436fab09cdc5ab35ebc5",
            "c421484e4dfe44d8b7287d83ecfe9035",
            "73740f71f43c42e3abb82b25f73c6710",
            "c75bd1926ca2468ab1755b105830e773",
            "461192d9ec46486990f630ecd60bda59",
            "9619761caf2144f7982cd9458d547f25",
            "87097003a68a444085036da483b3f201",
            "8e75b0d0db45405c94c7f8779b90f04e",
            "0b47afe1103348c0a7d9ffc83804be9e",
            "d77aba1d9f4d491ba28856e01b6bce3b",
            "8e4a9565fdba4a93bf94d3bf54276c55",
            "1627566d9391444f940c18d8d545988d"
          ]
        },
        "id": "IuMO0TnyHfVX",
        "outputId": "567e52b1-8cef-4293-8a44-afb85f05aed9",
        "collapsed": true
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a6e38cf4fb5c4e1c8626147d6924855c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train.csv:   0%|          | 0.00/11.3M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "348d5bbfa5724681a3d9e0c8cf3265ef"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "validation.csv: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "739433542ac24149b5909fa88d665159"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "test.csv: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fe114f25d39f48f783e9d469ad460eb5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/12460 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a05e308a2a4147a4b94c16a35dec3535"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/500 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5e7964873f3b4530a63935e9ad4d661d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/1500 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c421484e4dfe44d8b7287d83ecfe9035"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing **Qwen2.5-3B-Instruct**\n",
        "\n",
        "Since it is a **decoder-only (causal)** LLM, it’s not a native seq2seq model, but it can be still used it for seq2seq tasks by **formatting** the input as a **“prompt → desired output”** sequence.\n",
        "\n",
        "One can simulate **seq2seq-style behavior** using prompting (**instruction format**), but internally it is still decoder-only."
      ],
      "metadata": {
        "id": "XuQCKA9fxhKw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch"
      ],
      "metadata": {
        "id": "BePzjndupo9h"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = \"Qwen/Qwen2.5-3B-Instruct\""
      ],
      "metadata": {
        "id": "R4gleyR-t2lR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "7bfd62d875ed47ec98c12976bba4ef76",
            "dc6973d883d64d05925891e9ba8db615",
            "b7eace86a5764295bb55f0b82506dddc",
            "eeb1c434d3ee407c90945adfe1c91d4d",
            "ee0f910df38142828116b313fb74bf31",
            "da7355a58ccc46378d4499e2715a3467",
            "86ed9587e2b54fbc95acbae4c355f141",
            "5077b62a40d54d9199a3e281cf7f66df",
            "c500cb307ed24db5a77e267465ccf497",
            "23f8997a2eaf497b90919bd0879335a1",
            "3165cd81dcbe43939e3591cd74bc309f",
            "6b08cefc2e814a39b76fe7d2133372ac",
            "75a3a45f34e644d680dc24b5c6b60a7b",
            "d7e575df93254a99964d48782cd229f0",
            "0eefbaee7ca349ceabf219386627e5d3",
            "39aab423536448d083e38ef873605e57",
            "a8db88d5ce30452cb2e85610d9165637",
            "ab630d651ae045d2804e6271a10ca85b",
            "7b7973e615214e159ccf72eccf7bcfda",
            "269785946e12458cab1be33027989458",
            "b086197cf8b047669573d28e8452a57e",
            "48164ab5f86a4081b34f5563e4b9f412",
            "f7b16ab1c4fb4e1cb9ada2fd680a31f4",
            "4fa10b417a3d4888a4640b7763368e7f",
            "165570fd3d824335a036c71afcaea75a",
            "d2f8512c29ed42ef8b595ef195216315",
            "1710de8fdbbd4119ad8ff39720165431",
            "4ae35ee69618436e96046d77f7efa897",
            "5aceaebaf4034314a671c32408e03bfa",
            "4d29cdd52e314889b219796cc5a24a22",
            "2ca74cc088084ea4821f73a1bc58954a",
            "179f30737878406ebc4c65f3c1797038",
            "c2004cf9bbc041d3b15e15f587ef52df",
            "7f90162efed8456fa2dbf40b7afe218a",
            "24b2d65ce12440f28b11fd59b30b203b",
            "5b971a54a4c741d2ab112d215c4947a2",
            "e0b44a5fc8884a089ca9a77c72b94b97",
            "7c930284908447ee8f786a6721511b30",
            "e93399b51ec84c908a6c6877faf63868",
            "fa054bdea7a94d63accf6a078461b103",
            "1099c97cf0564277848d01ce3ee11348",
            "83d85536238a42b8a0bbfc0376b5bda1",
            "fed68d9d747c476ba439044344126f2e",
            "e04edab5dc104322b9e95634e9c24216"
          ]
        },
        "collapsed": true,
        "id": "vlTBoxaGo9Ct",
        "outputId": "2fe25796-4e72-41e5-9e42-612286fd8040"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7bfd62d875ed47ec98c12976bba4ef76"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6b08cefc2e814a39b76fe7d2133372ac"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f7b16ab1c4fb4e1cb9ada2fd680a31f4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7f90162efed8456fa2dbf40b7afe218a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    torch_dtype=\"auto\",\n",
        "    device_map=\"auto\" # ensures it uses GPU if available\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258,
          "referenced_widgets": [
            "8c6f363e16314c9a92a4ad9a8b3e95cc",
            "057db8070b634aea8701c42569ff1cb0",
            "21f469a13cc14ed4bf6f8549382efd69",
            "b48b69082a95471db00ab8955906d1d9",
            "e36a08e4885b437d87e0f8812862f126",
            "3aab5747dc2e47e49c7b51bfaa19428b",
            "1211bb6f3f6b44ec97fa384759d20e78",
            "1fee44b47d8a4d80b69e1cb44bcb6f71",
            "15e842f370fb429098c4b2ad3196fb84",
            "7dfae5cbef8e459fbd4c5ee70a540da1",
            "6d287e94397d41b494822f4ae0ddbb3c",
            "3a8651e4db1846429ac05eb801e0d23d",
            "eb5e5ee285a647de89f24370a3f0d398",
            "5fff35372c54461db0e546102085171a",
            "789038ecf58142419c637319b7c5b214",
            "096acd01809f48bebb6daed2b185b2a0",
            "1c9cb2d6265c49f6817200dfefc49506",
            "a545dde7503a4127a608cabb77386654",
            "c9672cd4a5e549c2856f86eed8967886",
            "eb4fc608e6e54646a70381177aad0eee",
            "b4b5554ce6fe4cee9cc141af28cf999a",
            "1065efa9ab6249119529dd9880626829",
            "b478a9288d5f4c49bab3822715ab26d6",
            "8b344412933f4a95837b90ac3ce6f859",
            "57ec2aca4780429c94109735ac5c4f27",
            "b6dd064ff7a640eb9d5101331ddf7cd7",
            "20ad8864047246d1950ef6e5e8d86676",
            "f62dfef3e53e4e359ae255003a2d2af7",
            "7ed3571301b046f789e1acc37dff4e57",
            "e80ff737648240eb95b0a05c91d2c8fb",
            "58cea324a0b2417cb957312565c5a8f3",
            "5ff395631abc41399e988ecedf84fbbf",
            "0982d033370941319237b26d29906f39",
            "798d59e9e80b462a9eeafca96a44e3a7",
            "dbb96d24aa8240f09c599a8462fc823b",
            "6e8d6e5b2f2a487f852c4f4b915932c7",
            "7046285afe7144cfae8725a98be2f61a",
            "d0e9757501f24a7e851650a977067523",
            "984720c0fdee4104875d133368006dd8",
            "5b3f24445edf4ca19287fd9b371f9193",
            "f1428c2700c54ede9f0877883c8ea90f",
            "761a0c45ed4449c198212ea7eb7c3708",
            "a5674d152743481588f1ae5db2766d25",
            "efe1a3621a7345a78e003cca85137048",
            "2503eaed95064deeaeacd8ab3900d050",
            "5bea67b8f2c642eeb9a1c6d6b6f490d2",
            "78d68578c95d45188bfd2f2b12d560a0",
            "51719890467d4e149443c2a354735c2d",
            "c19da4584c664359a4ec678cc699b269",
            "ca4eea3905004088b234674b75815adf",
            "653f510074e54629a31848b47b867829",
            "afefdee99b5540bca16475b503162555",
            "4fb621aecf284861a913c5fb232930d0",
            "a5c3493601be4926b0ecc3627a35eb87",
            "bb35de7a34d442bd877837c50f1e789c",
            "dfb50367fba941dc93cc13f56c4b2efe",
            "2811f7711fbf4614a8da90bd85cd82ae",
            "289ee488275e4cf395daf51b340e3d4a",
            "2a1b3ae04c9e419c9962dbdb3364e112",
            "ea2376392da944abba8f6222857a6ae0",
            "099ef2823f5e49bbaa9a0b704aa77854",
            "498e425b683f4b33bad1a459a891c262",
            "ec2ff9dcca944669a78ad07d38d1839e",
            "48054536d8eb41009ee55be56fc5a43e",
            "aa8069730bb9407881ca19348d93b45e",
            "70afc0c542a34ef98929a71f933bf6d6",
            "8e4ecfe07fb74656a4da25c055f4e30a",
            "76935b86eb934e8d9fc7ba572bcdb682",
            "77cab966710649ff842d04f98605a96b",
            "2bafc1a5ed314ee5918b6a7d61847d97",
            "5890fa7b315e452a90d4f8ab8c458444",
            "8d03890b5e804c7ab23825239e9b756c",
            "c55f784ff03c4aaf9e36c687e45ae045",
            "0c883b25f6f642e28910f0c81d0569d1",
            "f7d54efcc7d4496c984556901e7614a5",
            "9930a4e991cd48829797ab7b6227601c",
            "b0dfe273929f4fa0897ea98fecacd128"
          ]
        },
        "id": "PyzTpxobpCEk",
        "outputId": "0383617b-6e43-4a46-f86c-2da2d9b5101f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/661 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8c6f363e16314c9a92a4ad9a8b3e95cc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3a8651e4db1846429ac05eb801e0d23d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b478a9288d5f4c49bab3822715ab26d6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/3.97G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "798d59e9e80b462a9eeafca96a44e3a7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/2.20G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2503eaed95064deeaeacd8ab3900d050"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dfb50367fba941dc93cc13f56c4b2efe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/242 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8e4ecfe07fb74656a4da25c055f4e30a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index = 200\n",
        "dialogue = dataset['test'][index]['dialogue']\n",
        "summary = dataset['test'][index]['summary']\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Summarize the following dialogue as short as possible:\n",
        "\n",
        "{dialogue}\n",
        "\n",
        "\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "yNR9GMwB4WVu"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are Qwen, created by Alibaba Cloud. You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": prompt}\n",
        "]"
      ],
      "metadata": {
        "id": "btfjc_7M21Ml"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True\n",
        ")"
      ],
      "metadata": {
        "id": "SLCN48K3o_zu"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)"
      ],
      "metadata": {
        "id": "RKBKAMSC4ojO"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generated_ids = model.generate(\n",
        "    **model_inputs,\n",
        "    max_new_tokens=50\n",
        ")"
      ],
      "metadata": {
        "id": "uFTXflEq41MW"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generated_ids = [\n",
        "    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
        "]"
      ],
      "metadata": {
        "id": "5ToFXfLj9KxL"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]"
      ],
      "metadata": {
        "id": "1-HNG_2n446s"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Dialogue: \\n{dialogue}\\n')\n",
        "\n",
        "print(f'Generated Summary: {response}\\n')\n",
        "\n",
        "print(f'Human Summary: {summary}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxyYod7a493_",
        "outputId": "66c98528-9b64-4cd8-8409-2efe5dfa460b"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dialogue: \n",
            "#Person1#: Have you considered upgrading your system?\n",
            "#Person2#: Yes, but I'm not sure what exactly I would need.\n",
            "#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n",
            "#Person2#: That would be a definite bonus.\n",
            "#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n",
            "#Person2#: How can we do that?\n",
            "#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n",
            "#Person2#: No.\n",
            "#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n",
            "#Person2#: That sounds great. Thanks.\n",
            "\n",
            "Generated Summary: Person1 suggests Person2 consider adding a painting program for creating flyers and banners, and upgrading hardware including a faster processor, more powerful hard disk, more memory, a faster modem, and a CD-ROM drive. Person2 agrees and thanks Person1.\n",
            "\n",
            "Human Summary: #Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n"
          ]
        }
      ]
    }
  ]
}